{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f0f4266",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "430304a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc, re, csv\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c2e04e",
   "metadata": {},
   "source": [
    "# Parsing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a59d60",
   "metadata": {},
   "source": [
    "## Parse GO graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b957090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from https://www.kaggle.com/code/seddiktrk/cafa-6-blend-goa-negative-propagation/notebook\n",
    "\n",
    "def parse_obo(go_obo_path):\n",
    "    parents = defaultdict(set)\n",
    "    children = defaultdict(set)\n",
    "\n",
    "    if not os.path.exists(go_obo_path):\n",
    "        return parents, children\n",
    "\n",
    "    with open(go_obo_path, \"r\") as f:\n",
    "        cur_id = None\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"[Term]\":\n",
    "                cur_id = None\n",
    "            elif line.startswith(\"id: \"):\n",
    "                cur_id = line.split(\"id: \")[1].strip()\n",
    "            elif line.startswith(\"is_a: \"):\n",
    "                pid = line.split()[1].strip()\n",
    "                if cur_id:\n",
    "                    parents[cur_id].add(pid)\n",
    "                    children[pid].add(cur_id)\n",
    "            elif line.startswith(\"relationship: part_of \"):\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 3:\n",
    "                    pid = parts[2].strip()\n",
    "                    if cur_id:\n",
    "                        parents[cur_id].add(pid)\n",
    "                        children[pid].add(cur_id)\n",
    "    print(f\"[io] Parsed OBO: {len(parents)} nodes with parents\")\n",
    "    return parents, children\n",
    "\n",
    "\n",
    "def get_ancestors(go_id, parents):\n",
    "    ans = set()\n",
    "    stack = [go_id]\n",
    "    while stack:\n",
    "        cur = stack.pop()\n",
    "        for p in parents.get(cur, []):\n",
    "            if p not in ans:\n",
    "                ans.add(p)\n",
    "                stack.append(p)\n",
    "    return ans\n",
    "\n",
    "\n",
    "def get_descendants(go_id, children):\n",
    "    desc = set()\n",
    "    stack = [go_id]\n",
    "    while stack:\n",
    "        cur = stack.pop()\n",
    "        for child in children.get(cur, []):\n",
    "            if child not in desc:\n",
    "                desc.add(child)\n",
    "                stack.append(child)\n",
    "    return desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a66ce2",
   "metadata": {},
   "source": [
    "## Parse train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14f0f77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_df = pd.read_csv(os.path.join(\"./Train/train_terms.tsv\"), sep=\"\\t\", usecols=[\"EntryID\", \"term\"])\n",
    "train_annotations = terms_df.groupby(\"EntryID\")[\"term\"].apply(list).to_dict()\n",
    "\n",
    "train_sq = []\n",
    "train_answer = []\n",
    "\n",
    "terms_to_answer = terms_df.groupby('EntryID')['term'].apply(list).to_dict()\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "\n",
    "for record in SeqIO.parse(os.path.join(\"./Train/train_sequences.fasta\"), \"fasta\"):\n",
    "    try:\n",
    "        if \"|\" in record.id:\n",
    "            clean_id = record.id.split(\"|\")[1]\n",
    "        else:\n",
    "            clean_id = record.id\n",
    "        a = record.description.split(\"OX=\")\n",
    "        b = a[1].split(\" \")[0]\n",
    "        if clean_id:\n",
    "            train_sq.append({\n",
    "                \"id\": clean_id,\n",
    "                \"tax\": b,\n",
    "                \"seq\": str(record.seq),\n",
    "                \"answer\": terms_to_answer[clean_id]\n",
    "            })\n",
    "        else:\n",
    "            print(\"123\")\n",
    "    except IndexError:\n",
    "        continue\n",
    "\n",
    "test_sq = []\n",
    "\n",
    "for record in SeqIO.parse(os.path.join(\"./Test/testsuperset.fasta\"), \"fasta\"):\n",
    "    tax = record.description.split(\" \")[1]\n",
    "    # if (tax not in test_gr):\n",
    "    #     test_gr[tax] = []\n",
    "    test_sq.append({\n",
    "        \"id\": record.id,\n",
    "        \"tax\": tax,\n",
    "        \"seq\": str(record.seq)\n",
    "    })\n",
    "\n",
    "test_df = pd.DataFrame(test_sq)\n",
    "train_df = pd.DataFrame(train_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50f8a760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82404 224309\n",
      "  EntryID        term\n",
      "0  Q5W0B1  GO:0000785\n",
      "1  Q5W0B1  GO:0004842\n",
      "2  Q5W0B1  GO:0051865\n",
      "3  Q5W0B1  GO:0006275\n",
      "4  Q5W0B1  GO:0006513\n",
      "5  Q5W0B1  GO:0003682\n",
      "6  Q5W0B1  GO:0005515\n",
      "7  Q3EC77  GO:0000138\n",
      "8  Q3EC77  GO:0005794\n",
      "9  Q8IZR5  GO:0005515\n",
      "           id   tax                                                seq  \\\n",
      "0  A0A0C5B5G6  9606                                   MRWQEMGYIFYPRKLR   \n",
      "1      A0JNW5  9606  MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL...   \n",
      "2      A0JP26  9606  MVAEVCSMPAASAVKKPFDLRSKMGKWCHHRFPCCRGSGKSNMGTS...   \n",
      "3      A0PK11  9606  MPGWFKKAWYGLASLLSFSSFILIIVALVVPHWLSGKILCQTGVDL...   \n",
      "4      A1A4S6  9606  MGLQPLEFSDCYLDSPWFRERIRAHEAELERTNKFIKELIKDGKNL...   \n",
      "5      A1A519  9606  MKRRQKRKHLENEESQETAEKGGGMSKSQEDALQPGSTRVAKGWSQ...   \n",
      "6      A1L190  9606  MDDADPEERNYDNMLKMLSDLNKDLEKLLEEMEKISVQATWMAYDM...   \n",
      "7      A1L3X0  9606  MAFSDLTSRTVHLYDNWIKDADPRVEDWLLMSSPLPQTILLGFYVY...   \n",
      "8      A1X283  9606  MPPRRSIVEVKVLDVQKRRVPNKHYVYIIRVTWSSGSTEAIYRRYS...   \n",
      "9      A2A2Y4  9606  MFASCHCVPRGRRTMKMIHFRSSSVKSLSQEMRCTIRLLDDSEISC...   \n",
      "\n",
      "                                              answer  \n",
      "0  [GO:0001649, GO:0033687, GO:0005615, GO:000563...  \n",
      "1  [GO:0120013, GO:0034498, GO:0005769, GO:012000...  \n",
      "2                                       [GO:0005515]  \n",
      "3                           [GO:0007605, GO:0005515]  \n",
      "4  [GO:0005829, GO:0010008, GO:0005515, GO:000509...  \n",
      "5               [GO:0005634, GO:0045893, GO:0006366]  \n",
      "6                                       [GO:0005515]  \n",
      "7  [GO:0005515, GO:0009922, GO:0035338, GO:000578...  \n",
      "8  [GO:0005515, GO:0006801, GO:0072657, GO:000150...  \n",
      "9                                       [GO:0005515]  \n",
      "           id   tax                                                seq\n",
      "0  A0A0C5B5G6  9606                                   MRWQEMGYIFYPRKLR\n",
      "1  A0A1B0GTW7  9606  MLLLLLLLLLLPPLVLRVAASRCLHDETQKSVSLLRPPFSQLPSKS...\n",
      "2      A0JNW5  9606  MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL...\n",
      "3      A0JP26  9606  MVAEVCSMPAASAVKKPFDLRSKMGKWCHHRFPCCRGSGKSNMGTS...\n",
      "4      A0PK11  9606  MPGWFKKAWYGLASLLSFSSFILIIVALVVPHWLSGKILCQTGVDL...\n",
      "5      A1A4S6  9606  MGLQPLEFSDCYLDSPWFRERIRAHEAELERTNKFIKELIKDGKNL...\n",
      "6      A1A519  9606  MKRRQKRKHLENEESQETAEKGGGMSKSQEDALQPGSTRVAKGWSQ...\n",
      "7      A1L190  9606  MDDADPEERNYDNMLKMLSDLNKDLEKLLEEMEKISVQATWMAYDM...\n",
      "8      A1L3X0  9606  MAFSDLTSRTVHLYDNWIKDADPRVEDWLLMSSPLPQTILLGFYVY...\n",
      "9      A1X283  9606  MPPRRSIVEVKVLDVQKRRVPNKHYVYIIRVTWSSGSTEAIYRRYS...\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df), len(test_df))\n",
    "print(terms_df[:10])\n",
    "print(train_df[:10])\n",
    "print(test_df[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec5cf5c",
   "metadata": {},
   "source": [
    "# Getting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e70e69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bigrams(seq):\n",
    "    return [seq[i:i+2] for i in range(len(seq)-1)]\n",
    "\n",
    "def build_idf(train_seqs, vocab):\n",
    "    df = Counter()\n",
    "    total_docs = len(train_seqs)\n",
    "\n",
    "    for seq in train_seqs:\n",
    "        bigs = set(get_bigrams(seq))\n",
    "        for b in bigs:\n",
    "            if b in vocab:\n",
    "                df[b] += 1\n",
    "\n",
    "    idf = {}\n",
    "    for b in vocab:\n",
    "        idf[b] = math.log((1 + total_docs) / (1 + df[b])) + 1\n",
    "\n",
    "    return idf\n",
    "\n",
    "def seq_to_tfidf_vector(seq, vocab, idf, norm=True):\n",
    "    bigs = get_bigrams(seq)\n",
    "    count = Counter(bigs)\n",
    "\n",
    "    vec = np.zeros(len(vocab), dtype=float)\n",
    "\n",
    "    for i, b in enumerate(vocab):\n",
    "        tf = count[b]\n",
    "        vec[i] = tf * idf[b]\n",
    "\n",
    "    if norm:\n",
    "        s = np.linalg.norm(vec)\n",
    "        if s > 0:\n",
    "            vec = vec / s\n",
    "\n",
    "    return vec\n",
    "\n",
    "def build_feature_matrix(seqs, vocab, idf):\n",
    "    return np.array([seq_to_tfidf_vector(seq, vocab, idf) for seq in seqs])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39f7838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['LL', 'SS', 'SL', 'LS', 'AA', 'LA', 'AL', 'EE', 'LE', 'VL', 'EL', 'LV', 'LG', 'GL', 'LK', 'AS', 'GS', 'LR', 'SG', 'KL', 'GG', 'LP', 'TL', 'SA', 'IL', 'RL', 'LT', 'DL', 'LD', 'EK', 'EA', 'AV', 'KK', 'VS', 'AG', 'SV', 'PS', 'SP', 'VA', 'LQ', 'LI', 'KE', 'ST', 'TS', 'PL', 'SE', 'AE', 'GA', 'VV', 'PP', 'SK', 'IS', 'QL', 'FL', 'ES', 'SR', 'ED', 'KS', 'NL', 'KA', 'SI', 'GV', 'DS', 'PA', 'VE', 'TA', 'AT', 'EV', 'SD', 'PG', 'RS', 'RR', 'GK',\n",
    "            'DE', 'GE', 'TV', 'AK', 'VG', 'PE', 'TG', 'EG', 'AR', 'ER', 'AP', 'GT', 'TT', 'RE', 'EI', 'IA', 'NS', 'DG', 'GR', 'RK', 'FS', 'PV', 'DV', 'VD', 'SN', 'VI', 'ET', 'VP', 'TP', 'RG', 'GD', 'SQ', 'AD', 'DD', 'SF', 'KI', 'KT', 'GP', 'RV', 'IE', 'QQ', 'IG', 'VR', 'QA', 'TI', 'IP', 'KP', 'DK', 'KN', 'RI', 'DP', 'GF', 'GN', 'IR', 'EP', 'PD', 'NV', 'RP', 'QK', 'NE', 'HL', 'FV', 'GQ', 'DR', 'DF', 'IF', 'SY', 'RF', 'GY', 'TQ', 'FP', 'HP', 'VC', 'GC', 'GW']\n",
    "\n",
    "idf = build_idf(train_df[\"seq\"], features)\n",
    "X_train = build_feature_matrix(train_df[\"seq\"], features, idf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7278cfab",
   "metadata": {},
   "source": [
    "# Get label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6efe299b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82404, 26125)\n"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "y_train = mlb.fit_transform(train_df[\"answer\"])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e399e39b",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02a7cf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   55.8s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.2min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m clf = OneVsRestClassifier(LogisticRegression(max_iter=\u001b[32m500\u001b[39m, random_state=\u001b[32m42\u001b[39m, n_jobs=-\u001b[32m1\u001b[39m), n_jobs=-\u001b[32m1\u001b[39m, verbose=\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TuanLe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TuanLe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\multiclass.py:376\u001b[39m, in \u001b[36mOneVsRestClassifier.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    372\u001b[39m columns = (col.toarray().ravel() \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m Y.T)\n\u001b[32m    373\u001b[39m \u001b[38;5;66;03m# In cases where individual estimators are very fast to train setting\u001b[39;00m\n\u001b[32m    374\u001b[39m \u001b[38;5;66;03m# n_jobs > 1 in can results in slower performance due to the overhead\u001b[39;00m\n\u001b[32m    375\u001b[39m \u001b[38;5;66;03m# of spawning threads.  See joblib issue #112.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m376\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_binary\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnot \u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m%\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_binarizer_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlabel_binarizer_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators_[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mn_features_in_\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    391\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_features_in_ = \u001b[38;5;28mself\u001b[39m.estimators_[\u001b[32m0\u001b[39m].n_features_in_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TuanLe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TuanLe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TuanLe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TuanLe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(LogisticRegression(max_iter=500, random_state=42, n_jobs=-1), n_jobs=-1, verbose=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff6a64e",
   "metadata": {},
   "source": [
    "# Get output from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3eba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = build_feature_matrix(test_df[\"seq\"], features, idf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb7a9ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A0A0C5B5G6'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "arr = test_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f4a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict for [0, 32768]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m X_batch = X_test[i:i+batch_size]\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# predict proba\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m prob_batch = \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape (batch, n_classes)\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# lọc theo threshold\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j, prob_vec \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(prob_batch):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TuanLe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\multiclass.py:548\u001b[39m, in \u001b[36mOneVsRestClassifier.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    545\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    546\u001b[39m \u001b[38;5;66;03m# Y[i, j] gives the probability that sample i has the label j.\u001b[39;00m\n\u001b[32m    547\u001b[39m \u001b[38;5;66;03m# In the multi-label case, these are not disjoint.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m548\u001b[39m Y = np.array([\u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[32m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.estimators_]).T\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.estimators_) == \u001b[32m1\u001b[39m:\n\u001b[32m    551\u001b[39m     \u001b[38;5;66;03m# Only one estimator, but we still want to return probabilities\u001b[39;00m\n\u001b[32m    552\u001b[39m     \u001b[38;5;66;03m# for two classes.\u001b[39;00m\n\u001b[32m    553\u001b[39m     Y = np.concatenate(((\u001b[32m1\u001b[39m - Y), Y), axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TuanLe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1462\u001b[39m, in \u001b[36mLogisticRegression.predict_proba\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m   1457\u001b[39m ovr = \u001b[38;5;28mself\u001b[39m.multi_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33movr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1458\u001b[39m     \u001b[38;5;28mself\u001b[39m.multi_class \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdeprecated\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1459\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.classes_.size <= \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.solver == \u001b[33m\"\u001b[39m\u001b[33mliblinear\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1460\u001b[39m )\n\u001b[32m   1461\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ovr:\n\u001b[32m-> \u001b[39m\u001b[32m1462\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_predict_proba_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1463\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1464\u001b[39m     decision = \u001b[38;5;28mself\u001b[39m.decision_function(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TuanLe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:390\u001b[39m, in \u001b[36mLinearClassifierMixin._predict_proba_lr\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_predict_proba_lr\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Probability estimation for OvR logistic regression.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Positive class probabilities are computed as\u001b[39;00m\n\u001b[32m    387\u001b[39m \u001b[33;03m    1. / (1. + np.exp(-self.decision_function(X)));\u001b[39;00m\n\u001b[32m    388\u001b[39m \u001b[33;03m    multiclass is handled by normalizing that over all classes.\u001b[39;00m\n\u001b[32m    389\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m     prob = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    391\u001b[39m     expit(prob, out=prob)\n\u001b[32m    392\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prob.ndim == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TuanLe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:352\u001b[39m, in \u001b[36mLinearClassifierMixin.decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    349\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    350\u001b[39m xp, _ = get_namespace(X)\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    353\u001b[39m scores = safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m.coef_.T, dense_output=\u001b[38;5;28;01mTrue\u001b[39;00m) + \u001b[38;5;28mself\u001b[39m.intercept_\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[32m    355\u001b[39m     xp.reshape(scores, (-\u001b[32m1\u001b[39m,))\n\u001b[32m    356\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (scores.ndim > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m scores.shape[\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m)\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m scores\n\u001b[32m    358\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TuanLe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2954\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2952\u001b[39m         out = X, y\n\u001b[32m   2953\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2954\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2955\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2956\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TuanLe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TuanLe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:116\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;66;03m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# everything is finite; fall back to O(n) space `np.isinf/isnan` or custom\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# Cython implementation to prevent false positives and provide a detailed\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;66;03m# error message.\u001b[39;00m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(over=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     first_pass_isfinite = xp.isfinite(\u001b[43mxp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TuanLe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:2466\u001b[39m, in \u001b[36msum\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, initial, where)\u001b[39m\n\u001b[32m   2463\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m   2464\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n\u001b[32m-> \u001b[39m\u001b[32m2466\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msum\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\TuanLe\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:86\u001b[39m, in \u001b[36m_wrapreduction\u001b[39m\u001b[34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis=axis, out=out, **passkwargs)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32768   # hoặc 10, 32 tùy RAM\n",
    "threshold = 0.02  # THRESHOLD BẠN MUỐN\n",
    "\n",
    "all_probs = []\n",
    "\n",
    "for i in range(0, X_test.shape[0], batch_size):\n",
    "    print(f\"Predict for [{i}, {i+batch_size}]\")\n",
    "    X_batch = X_test[i:i+batch_size]\n",
    "\n",
    "    # predict proba\n",
    "    prob_batch = clf.predict_proba(X_batch)  # shape (batch, n_classes)\n",
    "\n",
    "    # lọc theo threshold\n",
    "    for j, prob_vec in enumerate(prob_batch):\n",
    "        cur_id = arr[i+j]\n",
    "        filtered = []\n",
    "        for class_idx, p in enumerate(prob_vec):\n",
    "            if p >= threshold:\n",
    "                label = mlb.classes_[class_idx]\n",
    "                filtered.append((label, float(p)))   # (GO_label, prob)\n",
    "\n",
    "\n",
    "        all_probs.append({\"id\": cur_id, \"preds\": filtered})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83260a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'A0A0C5B5G6', 'preds': []},\n",
       " {'id': 'A0A1B0GTW7', 'preds': [('GO:0005515', 0.5318793590021064)]},\n",
       " {'id': 'A0JNW5',\n",
       "  'preds': [('GO:0005515', 0.5373972077343487),\n",
       "   ('GO:0005634', 0.3366663596828987),\n",
       "   ('GO:0005737', 0.20013504702171248),\n",
       "   ('GO:0005829', 0.20207630022082895)]},\n",
       " {'id': 'A0JP26',\n",
       "  'preds': [('GO:0005515', 0.5490279628115253),\n",
       "   ('GO:0005634', 0.26516550266480643)]},\n",
       " {'id': 'A0PK11',\n",
       "  'preds': [('GO:0005515', 0.2009410212778832),\n",
       "   ('GO:0005886', 0.3099333448417127)]},\n",
       " {'id': 'A1A4S6',\n",
       "  'preds': [('GO:0005515', 0.6489025341207314),\n",
       "   ('GO:0005829', 0.22149986596519217)]},\n",
       " {'id': 'A1A519',\n",
       "  'preds': [('GO:0005515', 0.7235551952847804),\n",
       "   ('GO:0005634', 0.26682648261967745)]},\n",
       " {'id': 'A1L190',\n",
       "  'preds': [('GO:0005515', 0.5523456479797285),\n",
       "   ('GO:0005829', 0.20431734189759046)]},\n",
       " {'id': 'A1L3X0', 'preds': [('GO:0005515', 0.2324389204897821)]},\n",
       " {'id': 'A1X283', 'preds': [('GO:0005515', 0.5949344346076535)]},\n",
       " {'id': 'A2A2Y4', 'preds': [('GO:0005515', 0.6121940695372259)]},\n",
       " {'id': 'A2RU14',\n",
       "  'preds': [('GO:0005783', 0.24344678360611643),\n",
       "   ('GO:0005789', 0.21439939160894733),\n",
       "   ('GO:0005886', 0.3884665710799566)]},\n",
       " {'id': 'A2RUB6',\n",
       "  'preds': [('GO:0005515', 0.6254211971734027),\n",
       "   ('GO:0005634', 0.34412481399268124)]},\n",
       " {'id': 'A2RUC4',\n",
       "  'preds': [('GO:0005515', 0.42792160340468177),\n",
       "   ('GO:0005634', 0.21336416743669645)]},\n",
       " {'id': 'A4D1B5', 'preds': [('GO:0005515', 0.4093009889364991)]},\n",
       " {'id': 'A4GXA9',\n",
       "  'preds': [('GO:0005515', 0.602889014014424),\n",
       "   ('GO:0005886', 0.23369651762478458)]},\n",
       " {'id': 'A5D8V7',\n",
       "  'preds': [('GO:0005515', 0.6752848125456546),\n",
       "   ('GO:0005634', 0.2145895686363195),\n",
       "   ('GO:0005829', 0.31513961474982566)]},\n",
       " {'id': 'A5PLL7',\n",
       "  'preds': [('GO:0005515', 0.341857341216887),\n",
       "   ('GO:0005886', 0.20119831802177984)]},\n",
       " {'id': 'A6BM72',\n",
       "  'preds': [('GO:0005515', 0.43236141231939196),\n",
       "   ('GO:0005576', 0.3063342859930005),\n",
       "   ('GO:0005615', 0.23631245501629103),\n",
       "   ('GO:0031012', 0.23973499984010369)]},\n",
       " {'id': 'A6H8Y1',\n",
       "  'preds': [('GO:0005515', 0.637731529272744),\n",
       "   ('GO:0005634', 0.31476964609066954),\n",
       "   ('GO:0005829', 0.20887283090871045)]}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_probs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efec0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_probs[:20]\n",
    "\n",
    "output_file = \"submission.tsv\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for mp in all_probs:\n",
    "        # mp['id'], mp['pred']\n",
    "        for pred, prob in mp['preds']:\n",
    "            f.write(mp['id']+\"\\t\"+pred+\"\\t\"+str(round(prob, 3))+\"\\n\")\n",
    "\n",
    "# with open(output_file, \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow([\"id\", \"label\", \"probability\"])  # header\n",
    "\n",
    "#     for sample_idx, sample_id in enumerate(ids):\n",
    "#         for label_idx, label in enumerate(labels):\n",
    "#             prob = probs[sample_idx][label_idx]\n",
    "#             if prob >= threshold:\n",
    "#                 writer.writerow([sample_id, label, float(prob)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
