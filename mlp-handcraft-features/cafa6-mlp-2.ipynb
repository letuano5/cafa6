{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:35:06.486642Z",
     "iopub.status.busy": "2025-12-02T03:35:06.486324Z",
     "iopub.status.idle": "2025-12-02T03:35:09.715442Z",
     "shell.execute_reply": "2025-12-02T03:35:09.714718Z",
     "shell.execute_reply.started": "2025-12-02T03:35:06.486619Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install Bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-02T03:35:09.717207Z",
     "iopub.status.busy": "2025-12-02T03:35:09.716964Z",
     "iopub.status.idle": "2025-12-02T03:35:09.725933Z",
     "shell.execute_reply": "2025-12-02T03:35:09.725368Z",
     "shell.execute_reply.started": "2025-12-02T03:35:09.717179Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:35:09.726755Z",
     "iopub.status.busy": "2025-12-02T03:35:09.726553Z",
     "iopub.status.idle": "2025-12-02T03:35:09.745564Z",
     "shell.execute_reply": "2025-12-02T03:35:09.744834Z",
     "shell.execute_reply.started": "2025-12-02T03:35:09.726739Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os, gc, re, csv\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:35:09.747686Z",
     "iopub.status.busy": "2025-12-02T03:35:09.747213Z",
     "iopub.status.idle": "2025-12-02T03:35:09.761648Z",
     "shell.execute_reply": "2025-12-02T03:35:09.760860Z",
     "shell.execute_reply.started": "2025-12-02T03:35:09.747668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = './'\n",
    "is_kaggle = True\n",
    "if is_kaggle:\n",
    "    ROOT_DIR = '/kaggle/input/cafa-6-protein-function-prediction/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:35:09.776742Z",
     "iopub.status.busy": "2025-12-02T03:35:09.776258Z",
     "iopub.status.idle": "2025-12-02T03:35:09.798137Z",
     "shell.execute_reply": "2025-12-02T03:35:09.797495Z",
     "shell.execute_reply.started": "2025-12-02T03:35:09.776716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "AA_LIST = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "\n",
    "TOP_DI = ['AL', 'LA', 'LE', 'EA', 'AA', 'AS', 'SA', 'EL', 'LL', 'AE', 'SE', 'ES', 'GA', 'AG', 'VA', 'AV', 'LV', 'VL', 'LS', 'SL']\n",
    "\n",
    "TOP_TRI = ['ALA', 'LEA', 'EAL', 'LAL', 'AAA', 'LLE', 'ELE', 'ALE', 'GAL', 'ASA', 'VLA', 'LAV', 'SLS', 'LSL', 'GLA', 'LAG', 'AVL', 'VLA', 'SLE', 'LES']\n",
    "\n",
    "\n",
    "def compute_idf_aa(sequences):\n",
    "    df = Counter()\n",
    "    n = len(sequences)\n",
    "\n",
    "    for seq in sequences:\n",
    "        unique_aa = set(seq)\n",
    "        for aa in unique_aa:\n",
    "            if aa in AA_LIST:\n",
    "                df[aa] += 1\n",
    "\n",
    "    idf = {aa: math.log((n + 1) / (df[aa] + 1)) + 1 for aa in AA_LIST}\n",
    "    return idf\n",
    "\n",
    "\n",
    "def compute_idf_di(sequences):\n",
    "    df = Counter()\n",
    "    n = len(sequences)\n",
    "\n",
    "    for seq in sequences:\n",
    "        length = len(seq)\n",
    "        tokens = set(\n",
    "            seq[i:i+2] for i in range(length - 1)\n",
    "        )\n",
    "        for dp in tokens:\n",
    "            if dp in TOP_DI:\n",
    "                df[dp] += 1\n",
    "\n",
    "    idf = {dp: math.log((n + 1) / (df[dp] + 1)) + 1 for dp in TOP_DI}\n",
    "    return idf\n",
    "\n",
    "\n",
    "def compute_idf_tri(sequences):\n",
    "    df = Counter()\n",
    "    n = len(sequences)\n",
    "\n",
    "    for seq in sequences:\n",
    "        length = len(seq)\n",
    "        tokens = set(\n",
    "            seq[i:i+3] for i in range(length - 2)\n",
    "        )\n",
    "        for tp in tokens:\n",
    "            if tp in TOP_TRI:\n",
    "                df[tp] += 1\n",
    "\n",
    "    idf = {tp: math.log((n + 1) / (df[tp] + 1)) + 1 for tp in TOP_TRI}\n",
    "    return idf\n",
    "\n",
    "\n",
    "def compute_all_idf(sequences):\n",
    "    return {\n",
    "        \"idf_aa\": compute_idf_aa(sequences),\n",
    "        \"idf_di\": compute_idf_di(sequences),\n",
    "        \"idf_tri\": compute_idf_tri(sequences),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:35:09.799101Z",
     "iopub.status.busy": "2025-12-02T03:35:09.798903Z",
     "iopub.status.idle": "2025-12-02T03:35:09.820177Z",
     "shell.execute_reply": "2025-12-02T03:35:09.819650Z",
     "shell.execute_reply.started": "2025-12-02T03:35:09.799086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_sequence_features_tf_idf(\n",
    "    seq,\n",
    "    idf_aa=None,\n",
    "    idf_di=None,\n",
    "    idf_tri=None\n",
    "):\n",
    "\n",
    "    if not seq or len(seq) == 0:\n",
    "        return np.zeros(85)\n",
    "\n",
    "    length = len(seq)\n",
    "    aa_counts = Counter(seq)\n",
    "\n",
    "    aa_list = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "    tf_aa = np.array([aa_counts.get(a, 0) / length for a in aa_list])\n",
    "\n",
    "    if idf_aa is not None:\n",
    "        idf_vec = np.array([idf_aa.get(a, 1.0) for a in aa_list])\n",
    "        tfidf_aa = tf_aa * idf_vec\n",
    "    else:\n",
    "        tfidf_aa = tf_aa\n",
    "\n",
    "    hydrophobic = sum(aa_counts.get(a, 0) for a in 'AILMFWYV') / length\n",
    "    charged     = sum(aa_counts.get(a, 0) for a in 'DEKR') / length\n",
    "\n",
    "    aa_weights = {'A': 89, 'C': 121, 'D': 133, 'E': 147, 'F': 165, 'G': 75, 'H': 155, 'I': 131, 'K': 146, 'L': 131, 'M': 149, 'N': 132, 'P': 115, 'Q': 146, 'R': 174, 'S': 105, 'T': 119, 'V': 117, 'W': 204, 'Y': 181}\n",
    "\n",
    "    mol_weight = sum(aa_counts.get(a, 0) * aa_weights.get(a, 0) for a in aa_counts)\n",
    "\n",
    "    basic_features = np.array([\n",
    "        np.log1p(length),\n",
    "        hydrophobic,\n",
    "        charged,\n",
    "        np.log1p(mol_weight)\n",
    "    ])\n",
    "\n",
    "    \n",
    "    groups = {'hydrophobic': set('AILMFWYV'),'polar': set('STNQ'),'positive': set('RK'),'negative': set('DE'),'aromatic': set('FWY'),'aliphatic': set('ILV'),'small': set('ACDGNPSTV')}\n",
    "\n",
    "    ctd_features = np.array([\n",
    "        sum(1 for aa in seq if aa in g) / length for g in groups.values()\n",
    "    ])\n",
    "\n",
    "    \n",
    "    di_counts = Counter(seq[i:i+2] for i in range(length - 1))\n",
    "    denom_di = max(length - 1, 1)\n",
    "\n",
    "    tf_di = np.array([di_counts.get(dp, 0) / denom_di for dp in TOP_DI])\n",
    "\n",
    "    if idf_di is not None:\n",
    "        idf_vec_di = np.array([idf_di.get(dp, 1.0) for dp in TOP_DI])\n",
    "        tfidf_di = tf_di * idf_vec_di\n",
    "    else:\n",
    "        tfidf_di = tf_di\n",
    "\n",
    "    tri_counts = Counter(seq[i:i+3] for i in range(length - 2))\n",
    "    denom_tri = max(length - 2, 1)\n",
    "\n",
    "    tf_tri = np.array([tri_counts.get(tp, 0) / denom_tri for tp in TOP_TRI])\n",
    "\n",
    "    if idf_tri is not None:\n",
    "        idf_vec_tri = np.array([idf_tri.get(tp, 1.0) for tp in TOP_TRI])\n",
    "        tfidf_tri = tf_tri * idf_vec_tri\n",
    "    else:\n",
    "        tfidf_tri = tf_tri\n",
    "\n",
    "    \n",
    "    return np.concatenate([\n",
    "        tfidf_aa,\n",
    "        basic_features,\n",
    "        ctd_features,\n",
    "        tfidf_di,\n",
    "        tfidf_tri\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:35:09.837785Z",
     "iopub.status.busy": "2025-12-02T03:35:09.837548Z",
     "iopub.status.idle": "2025-12-02T03:35:09.850500Z",
     "shell.execute_reply": "2025-12-02T03:35:09.849754Z",
     "shell.execute_reply.started": "2025-12-02T03:35:09.837761Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_feature_matrix(seqs, idf_aa, idf_di, idf_tri):\n",
    "    return np.array([extract_sequence_features_tf_idf(seq, idf_aa, idf_di, idf_tri) for seq in seqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:35:09.853346Z",
     "iopub.status.busy": "2025-12-02T03:35:09.853159Z",
     "iopub.status.idle": "2025-12-02T03:35:09.864933Z",
     "shell.execute_reply": "2025-12-02T03:35:09.864280Z",
     "shell.execute_reply.started": "2025-12-02T03:35:09.853332Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = './'\n",
    "is_kaggle = True\n",
    "if is_kaggle:\n",
    "    ROOT_DIR = '/kaggle/input/cafa-6-protein-function-prediction/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:35:09.865801Z",
     "iopub.status.busy": "2025-12-02T03:35:09.865577Z",
     "iopub.status.idle": "2025-12-02T03:35:14.977489Z",
     "shell.execute_reply": "2025-12-02T03:35:14.976884Z",
     "shell.execute_reply.started": "2025-12-02T03:35:09.865782Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "terms_df = pd.read_csv(os.path.join(ROOT_DIR + \"Train/train_terms.tsv\"), sep=\"\\t\", usecols=[\"EntryID\", \"term\"])\n",
    "train_annotations = terms_df.groupby(\"EntryID\")[\"term\"].apply(list).to_dict()\n",
    "\n",
    "train_sq = []\n",
    "train_answer = []\n",
    "\n",
    "terms_to_answer = terms_df.groupby('EntryID')['term'].apply(list).to_dict()\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "\n",
    "for record in SeqIO.parse(os.path.join(ROOT_DIR + \"Train/train_sequences.fasta\"), \"fasta\"):\n",
    "    try:\n",
    "        if \"|\" in record.id:\n",
    "            clean_id = record.id.split(\"|\")[1]\n",
    "        else:\n",
    "            clean_id = record.id\n",
    "        a = record.description.split(\"OX=\")\n",
    "        b = a[1].split(\" \")[0]\n",
    "        if clean_id:\n",
    "            train_sq.append({\n",
    "                \"id\": clean_id,\n",
    "                \"tax\": b,\n",
    "                \"seq\": str(record.seq),\n",
    "                \"answer\": terms_to_answer[clean_id]\n",
    "            })\n",
    "        else:\n",
    "            print(\"123\")\n",
    "    except IndexError:\n",
    "        continue\n",
    "\n",
    "test_sq = []\n",
    "\n",
    "for record in SeqIO.parse(os.path.join(ROOT_DIR + \"Test/testsuperset.fasta\"), \"fasta\"):\n",
    "    tax = record.description.split(\" \")[1]\n",
    "    # if (tax not in test_gr):\n",
    "    #     test_gr[tax] = []\n",
    "    test_sq.append({\n",
    "        \"id\": record.id,\n",
    "        \"tax\": tax,\n",
    "        \"seq\": str(record.seq)\n",
    "    })\n",
    "\n",
    "test_df = pd.DataFrame(test_sq)\n",
    "train_df = pd.DataFrame(train_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:35:14.978389Z",
     "iopub.status.busy": "2025-12-02T03:35:14.978206Z",
     "iopub.status.idle": "2025-12-02T03:35:14.985873Z",
     "shell.execute_reply": "2025-12-02T03:35:14.985144Z",
     "shell.execute_reply.started": "2025-12-02T03:35:14.978374Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "features = ['LL', 'SS', 'SL', 'LS', 'AA', 'LA', 'AL', 'EE', 'LE', 'VL', 'EL', 'LV', 'LG', 'GL', 'LK', 'AS', 'GS', 'LR', 'SG', 'KL', 'GG', 'LP', 'TL', 'SA', 'IL', 'RL', 'LT', 'DL', 'LD', 'EK', 'EA', 'AV', 'KK', 'VS', 'AG', 'SV', 'PS', 'SP', 'VA', 'LQ', 'LI', 'KE', 'ST', 'TS', 'PL', 'SE', 'AE', 'GA', 'VV', 'PP', 'SK', 'IS', 'QL', 'FL', 'ES', 'SR', 'ED', 'KS', 'NL', 'KA', 'SI', 'GV', 'DS', 'PA', 'VE', 'TA', 'AT', 'EV', 'SD', 'PG', 'RS', 'RR', 'GK',\n",
    "            'DE', 'GE', 'TV', 'AK', 'VG', 'PE', 'TG', 'EG', 'AR', 'ER', 'AP', 'GT', 'TT', 'RE', 'EI', 'IA', 'NS', 'DG', 'GR', 'RK', 'FS', 'PV', 'DV', 'VD', 'SN', 'VI', 'ET', 'VP', 'TP', 'RG', 'GD', 'SQ', 'AD', 'DD', 'SF', 'KI', 'KT', 'GP', 'RV', 'IE', 'QQ', 'IG', 'VR', 'QA', 'TI', 'IP', 'KP', 'DK', 'KN', 'RI', 'DP', 'GF', 'GN', 'IR', 'EP', 'PD', 'NV', 'RP', 'QK', 'NE', 'HL', 'FV', 'GQ', 'DR', 'DF', 'IF', 'SY', 'RF', 'GY', 'TQ', 'FP', 'HP', 'VC', 'GC', 'GW']\n",
    "\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:35:14.986912Z",
     "iopub.status.busy": "2025-12-02T03:35:14.986600Z",
     "iopub.status.idle": "2025-12-02T03:36:19.695741Z",
     "shell.execute_reply": "2025-12-02T03:36:19.695107Z",
     "shell.execute_reply.started": "2025-12-02T03:35:14.986893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "idf_all = compute_all_idf(train_df[\"seq\"])\n",
    "\n",
    "idf_aa  = idf_all[\"idf_aa\"]\n",
    "idf_di  = idf_all[\"idf_di\"]\n",
    "idf_tri = idf_all[\"idf_tri\"]\n",
    "X_train = build_feature_matrix(train_df[\"seq\"], idf_aa, idf_di, idf_tri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:36:19.697054Z",
     "iopub.status.busy": "2025-12-02T03:36:19.696817Z",
     "iopub.status.idle": "2025-12-02T03:37:34.035941Z",
     "shell.execute_reply": "2025-12-02T03:37:34.035098Z",
     "shell.execute_reply.started": "2025-12-02T03:36:19.697030Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test = build_feature_matrix(test_df[\"seq\"], idf_aa, idf_di, idf_tri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:37:34.037701Z",
     "iopub.status.busy": "2025-12-02T03:37:34.037426Z",
     "iopub.status.idle": "2025-12-02T03:37:34.043682Z",
     "shell.execute_reply": "2025-12-02T03:37:34.043041Z",
     "shell.execute_reply.started": "2025-12-02T03:37:34.037683Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:37:34.044598Z",
     "iopub.status.busy": "2025-12-02T03:37:34.044341Z",
     "iopub.status.idle": "2025-12-02T03:37:35.139539Z",
     "shell.execute_reply": "2025-12-02T03:37:35.138826Z",
     "shell.execute_reply.started": "2025-12-02T03:37:34.044570Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "y_train = mlb.fit_transform(train_df[\"answer\"])\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:37:35.140492Z",
     "iopub.status.busy": "2025-12-02T03:37:35.140244Z",
     "iopub.status.idle": "2025-12-02T03:37:35.147840Z",
     "shell.execute_reply": "2025-12-02T03:37:35.147165Z",
     "shell.execute_reply.started": "2025-12-02T03:37:35.140449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float16 if torch.cuda.is_available() else torch.float32)\n",
    "        self.Y = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.Y[i]\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=1280, output_dim=None):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, output_dim) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:37:35.148858Z",
     "iopub.status.busy": "2025-12-02T03:37:35.148550Z",
     "iopub.status.idle": "2025-12-02T03:37:44.396719Z",
     "shell.execute_reply": "2025-12-02T03:37:44.395974Z",
     "shell.execute_reply.started": "2025-12-02T03:37:35.148841Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "lr = 1e-3\n",
    "\n",
    "dataset = ProteinDataset(X_train, y_train)\n",
    "val_size = int(0.1 * len(dataset))\n",
    "train_size = len(dataset) - val_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
    "\n",
    "model = MLP(input_dim=X_train.shape[1], output_dim=y_train.shape[1]).to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=2, verbose=True\n",
    ")\n",
    "scaler = GradScaler()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:37:44.398028Z",
     "iopub.status.busy": "2025-12-02T03:37:44.397447Z",
     "iopub.status.idle": "2025-12-02T03:42:30.749145Z",
     "shell.execute_reply": "2025-12-02T03:42:30.748479Z",
     "shell.execute_reply.started": "2025-12-02T03:37:44.398006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for Xb, Yb in train_loader:\n",
    "        Xb, Yb = Xb.to(device), Yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast():\n",
    "            logits = model(Xb)\n",
    "            loss = criterion(logits, Yb)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item() * Xb.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for Xb, Yb in val_loader:\n",
    "            Xb, Yb = Xb.to(device), Yb.to(device)\n",
    "            with autocast():\n",
    "                logits = model(Xb)\n",
    "                loss = criterion(logits, Yb)\n",
    "            val_loss += loss.item() * Xb.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"protein_mlp_best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:42:30.750147Z",
     "iopub.status.busy": "2025-12-02T03:42:30.749931Z",
     "iopub.status.idle": "2025-12-02T03:42:30.754375Z",
     "shell.execute_reply": "2025-12-02T03:42:30.753607Z",
     "shell.execute_reply.started": "2025-12-02T03:42:30.750124Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import autocast\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:42:30.755330Z",
     "iopub.status.busy": "2025-12-02T03:42:30.755117Z",
     "iopub.status.idle": "2025-12-02T03:42:30.772487Z",
     "shell.execute_reply": "2025-12-02T03:42:30.771895Z",
     "shell.execute_reply.started": "2025-12-02T03:42:30.755304Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "infer_batch_size = 32\n",
    "min_prob = 0.02\n",
    "top_k = None\n",
    "\n",
    "model_path = \"protein_mlp_best.pt\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:42:30.773381Z",
     "iopub.status.busy": "2025-12-02T03:42:30.773132Z",
     "iopub.status.idle": "2025-12-02T03:42:30.960107Z",
     "shell.execute_reply": "2025-12-02T03:42:30.959373Z",
     "shell.execute_reply.started": "2025-12-02T03:42:30.773359Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_inf = MLP(input_dim=X_train.shape[1], output_dim=y_train.shape[1]).to(device)\n",
    "state = torch.load(model_path, map_location=device)\n",
    "model_inf.load_state_dict(state)\n",
    "model_inf.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:42:30.961418Z",
     "iopub.status.busy": "2025-12-02T03:42:30.961059Z",
     "iopub.status.idle": "2025-12-02T03:42:33.845669Z",
     "shell.execute_reply": "2025-12-02T03:42:33.845068Z",
     "shell.execute_reply.started": "2025-12-02T03:42:30.961391Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def clean_id_for_matching(s):\n",
    "    if \"|\" in s:\n",
    "        parts = s.split(\"|\")\n",
    "        if len(parts) >= 2:\n",
    "            return parts[1]\n",
    "    return s\n",
    "\n",
    "train_id_to_terms = {}\n",
    "for idx, row in train_df.iterrows():\n",
    "    train_id_to_terms[clean_id_for_matching(row[\"id\"])] = row[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:42:33.846541Z",
     "iopub.status.busy": "2025-12-02T03:42:33.846308Z",
     "iopub.status.idle": "2025-12-02T03:42:33.868040Z",
     "shell.execute_reply": "2025-12-02T03:42:33.867346Z",
     "shell.execute_reply.started": "2025-12-02T03:42:33.846515Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float16 if torch.cuda.is_available() else torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T03:42:33.869264Z",
     "iopub.status.busy": "2025-12-02T03:42:33.869020Z",
     "iopub.status.idle": "2025-12-02T03:42:33.873199Z",
     "shell.execute_reply": "2025-12-02T03:42:33.872599Z",
     "shell.execute_reply.started": "2025-12-02T03:42:33.869241Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "n_test = X_test_tensor.shape[0]\n",
    "n_batches = math.ceil(n_test / infer_batch_size)\n",
    "\n",
    "all_probs = []  \n",
    "sigmoid = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T04:19:08.213206Z",
     "iopub.status.busy": "2025-12-02T04:19:08.212435Z",
     "iopub.status.idle": "2025-12-02T04:19:52.268300Z",
     "shell.execute_reply": "2025-12-02T04:19:52.267499Z",
     "shell.execute_reply.started": "2025-12-02T04:19:08.213181Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i in tqdm(range(n_batches), desc=\"Inference Batches\"):\n",
    "        start = i * infer_batch_size\n",
    "        end = min((i + 1) * infer_batch_size, n_test)\n",
    "        batch_X = X_test_tensor[start:end].to(device)\n",
    "\n",
    "        with autocast():\n",
    "            logits = model_inf(batch_X)\n",
    "            probs = sigmoid(logits)\n",
    "\n",
    "        probs = probs.cpu().numpy()\n",
    "\n",
    "        for j in range(probs.shape[0]):\n",
    "            idx_global = start + j\n",
    "            test_row = test_df.iloc[idx_global]\n",
    "            orig_test_id = test_row[\"id\"]\n",
    "            cleaned = clean_id_for_matching(orig_test_id)\n",
    "            \n",
    "            row_probs = probs[j] \n",
    "            \n",
    "            ge_idx = np.where(row_probs >= min_prob)[0]\n",
    "            sorted_idx = ge_idx[np.argsort(row_probs[ge_idx])[::-1]] if len(ge_idx) > 0 else []\n",
    "            selected = [(mlb.classes_[k], float(row_probs[k])) for k in sorted_idx]\n",
    "\n",
    "            all_probs.append({\"id\": orig_test_id, \"preds\": selected})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T04:19:57.891801Z",
     "iopub.status.busy": "2025-12-02T04:19:57.891519Z",
     "iopub.status.idle": "2025-12-02T04:20:14.495785Z",
     "shell.execute_reply": "2025-12-02T04:20:14.495000Z",
     "shell.execute_reply.started": "2025-12-02T04:19:57.891780Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_file = \"submission.tsv\"\n",
    "num_lines = 0\n",
    "with open(output_file, \"w\") as f:\n",
    "    for mp in all_probs:\n",
    "        if len(mp[\"preds\"]) == 0:\n",
    "            continue\n",
    "        for pred, prob in mp[\"preds\"]:\n",
    "            num_lines += 1\n",
    "            f.write(mp[\"id\"] + \"\\t\" + str(pred) + \"\\t\" + str(round(prob, 3)) + \"\\n\")\n",
    "\n",
    "print(f\"Wrote {output_file} with {len(all_probs)} entries and {num_lines} lines (some may have zero preds skipped).\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14084779,
     "sourceId": 116062,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
